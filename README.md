# Archi Query Master

Archi Query Master l√† m·ªôt n·ªÅn t·∫£ng AI RAG (Retrieval-Augmented Generation) ƒë·ªãnh h∆∞·ªõng modular gi√∫p:
- Ingest v√† x·ª≠ l√Ω t√†i li·ªáu (PDF ‚Üí OCR ‚Üí chunk ‚Üí embedding).
- Truy v·∫•n ng·ªØ nghƒ©a qua vector search + top-K contextualization.
- Tr·ª´u t∆∞·ª£ng h√≥a g·ªçi nhi·ªÅu nh√† cung c·∫•p AI (Gemini, OpenAI, Ollama, Anthropic, Groq‚Ä¶).
- H∆∞·ªõng t·ªõi v·∫≠n h√†nh production: ƒëa provider fallback, t·ªëi ∆∞u chi ph√≠, logging, m·ªü r·ªông, b·∫£o tr√¨.

‚ÄúSecond pass‚Äù README n√†y m·ªü r·ªông chi ti·∫øt h∆°n so v·ªõi b·∫£n ƒë·∫ßu: b·ªï sung bi·∫øn m√¥i tr∆∞·ªùng th·ª±c t·∫ø, m√¥ t·∫£ ki·∫øn tr√∫c RAG, chi·∫øn l∆∞·ª£c cost, provider selection, v√† c·∫•u tr√∫c m√£ ngu·ªìn d·ª± ki·∫øn (t·ª´ t√†i li·ªáu ki·∫øn tr√∫c).

## M·ª•c l·ª•c
1. T·∫ßm nh√¨n & Tri·∫øt l√Ω thi·∫øt k·∫ø  
2. Ki·∫øn tr√∫c RAG t·ªïng quan  
3. Multi-Provider Strategy & Provider Manager  
4. T√≠nh nƒÉng ch√≠nh (Feature Set)  
5. Stack c√¥ng ngh·ªá chi ti·∫øt  
6. C·∫•u tr√∫c th∆∞ m·ª•c & ƒê·ªãnh h∆∞·ªõng t·ªï ch·ª©c m√£ ngu·ªìn  
7. Bi·∫øn m√¥i tr∆∞·ªùng (.env)  
8. Scripts & Quy tr√¨nh ph√°t tri·ªÉn  
9. Pipeline Ingestion T√†i li·ªáu (PDF ‚Üí Embedding)  
10. Retrieval & Query Flow  
11. Prompt Composition & Generation  
12. T·ªëi ∆∞u chi ph√≠ & Fallback chi·∫øn l∆∞·ª£c  
13. Testing Strategy  
14. Production Hardening Checklist  
15. B·∫£o m·∫≠t & Qu·∫£n l√Ω kh√≥a  
16. T√≠ch h·ª£p v√†o h·ªá th·ªëng kh√°c (Embedding / API)  
17. Roadmap g·ª£i √Ω m·ªü r·ªông  
18. Kh·∫Øc ph·ª•c s·ª± c·ªë (Troubleshooting)  
19. T√†i li·ªáu tham chi·∫øu n·ªôi b·ªô  
20. Thi·∫øu / C·∫ßn b·ªï sung (Ghi ch√∫ duy tr√¨)  
21. License (Tr·∫°ng th√°i)  

---

## 1. T·∫ßm nh√¨n & Tri·∫øt l√Ω thi·∫øt k·∫ø
- Pluggable Providers: Thay ƒë·ªïi model ho·∫∑c nh√† cung c·∫•p kh√¥ng ph√° v·ª° l·ªõp nghi·ªáp v·ª•.
- Cost-Aware: ∆Øu ti√™n m√¥ h√¨nh free/fast cho truy v·∫•n ƒë∆°n gi·∫£n, m√¥ h√¨nh cao c·∫•p cho reasoning.
- Observability-First: C√≥ ch·ªó cho logging c√≥ c·∫•u tr√∫c, ƒëo th·ªùi gian, token usage.
- Data Ownership: H·ªó tr·ª£ m√¥ h√¨nh local (Ollama) ƒë·ªÉ d√πng offline / tƒÉng quy·ªÅn ri√™ng t∆∞.
- Evolvable Architecture: T√†i li·ªáu chia nh·ªè (architecture, implementation, provider, improvements) cho ph√©p m·ªü r·ªông.

## 2. Ki·∫øn tr√∫c RAG t·ªïng quan
Workflow (t·ª´ AI_BACKEND_ARCHITECTURE.md):

1. Ingestion (offline / batch):
   - PDF ‚Üí (OCR n·∫øu c·∫ßn) ‚Üí Chu·∫©n h√≥a ‚Üí Chunking ‚Üí Embedding ‚Üí L∆∞u vector DB.
2. Query (real-time):
   - User query ‚Üí Embedding ‚Üí Vector similarity search ‚Üí Top-K chunks.
3. Generation:
   - X√¢y d·ª±ng prompt (query + context) ‚Üí G·ªçi LLM (theo provider l·ª±a ch·ªçn) ‚Üí Streaming response (n·∫øu h·ªó tr·ª£).

Tr·∫°ng th√°i hi·ªán t·∫°i (theo doc):
- ‚úÖ Ingestion pipeline
- ‚úÖ Query embedding + search
- üîÑ Generation (ƒëa provider, context assembly)
  
## 3. Multi-Provider Strategy & Provider Manager
Logic ch·ªçn provider d·ª±a tr√™n:
- Default (VITE_DEFAULT_AI_PROVIDER).
- Lo·∫°i t√°c v·ª•: reasoning s√¢u / t√≥m t·∫Øt / conversational.
- Chi ph√≠ / t·ªëc ƒë·ªô: V√≠ d·ª• d√πng Gemini Flash (free) tr∆∞·ªõc, fallback OpenAI mini n·∫øu c·∫ßn ch·∫•t l∆∞·ª£ng cao h∆°n.
- Fallback: Khi timeout / l·ªói rate limit ‚Üí th·ª≠ provider kh√°c (c·∫•u tr√∫c providerManager.ts).

Provider Interface (tr·ª´u t∆∞·ª£ng):
```
interface AiProvider {
  name: string;
  supportsStreaming: boolean;
  generate(opts: { prompt: string; system?: string; temperature?: number; ... }): AsyncIterable<string> | string;
  embed(texts: string[]): Promise<number[][]>;
  health?(): Promise<boolean>;
}
```
(ƒê·ªãnh nghƒ©a c·ª• th·ªÉ xem trong providers/base.ts ‚Äì theo m√¥ t·∫£ ki·∫øn tr√∫c.)

## 4. T√≠nh nƒÉng ch√≠nh (Feature Set)
- PDF Parsing + OCR fallback (tesseract.js).
- Chunking + Overlap ƒë·ªÉ gi·ªØ ng·ªØ c·∫£nh.
- Embedding + vector search (Supabase pgvector ho·∫∑c t∆∞∆°ng ƒë∆∞∆°ng ‚Äì d·ª± ki·∫øn).
- Multi-provider LLM generation (Gemini / OpenAI / Ollama / Anthropic / Groq).
- UI c·∫•u h√¨nh provider (AIProviderSettings).
- RAG Query Engine: compose context ‚Üí g·ªçi model ‚Üí stream.
- Cost analysis & l·ª±a ch·ªçn chi·∫øn l∆∞·ª£c (documented).
- Upload improvements pipeline (gi·∫£m l·ªói PDF, chu·∫©n h√≥a text).
- Testing ƒëa t·∫ßng (unit / integration / provider contract / UI).

## 5. Stack c√¥ng ngh·ªá chi ti·∫øt
Frontend & UI:
- React 18, Vite, TypeScript
- Radix UI primitives + shadcn-ui
- Tailwind CSS + tailwind-merge + class-variance-authority
- React Query (qu·∫£n l√Ω async / cache)
- Form: react-hook-form + zod

AI & ML:
- openai
- @google/generative-ai
- @anthropic-ai/sdk
- groq-sdk
- @huggingface/transformers (embedding / local inference nh·∫π)
- Ollama (qua REST local)

PDF & Text:
- pdfjs-dist
- tesseract.js (OCR)
- Normalization logic (n·∫±m trong ingestion layer ‚Äì xem pipeline docs)

Testing:
- Vitest
- @testing-library/react / jest-dom
- jsdom ho·∫∑c happy-dom

Data:
- Supabase (auth, storage, vector) ‚Äì suy lu·∫≠n t·ª´ th∆∞ m·ª•c supabase
- Dexie (IndexedDB) ‚Äì caching ph√≠a client (n·∫øu c·∫ßn offline)

## 6. C·∫•u tr√∫c th∆∞ m·ª•c & ƒê·ªãnh h∆∞·ªõng t·ªï ch·ª©c m√£ ngu·ªìn
Theo s∆° ƒë·ªì trong AI_BACKEND_ARCHITECTURE.md (d·ª± ki·∫øn):
```
src/
‚îú‚îÄ services/
‚îÇ  ‚îî‚îÄ ai/
‚îÇ     ‚îú‚îÄ providers/
‚îÇ     ‚îÇ  ‚îú‚îÄ base.ts
‚îÇ     ‚îÇ  ‚îú‚îÄ openai.ts
‚îÇ     ‚îÇ  ‚îú‚îÄ gemini.ts
‚îÇ     ‚îÇ  ‚îú‚îÄ ollama.ts
‚îÇ     ‚îÇ  ‚îú‚îÄ anthropic.ts
‚îÇ     ‚îÇ  ‚îî‚îÄ groq.ts
‚îÇ     ‚îú‚îÄ ragEngine.ts
‚îÇ     ‚îú‚îÄ providerManager.ts
‚îÇ     ‚îî‚îÄ types.ts
‚îú‚îÄ hooks/
‚îÇ  ‚îî‚îÄ useAIChat.ts
‚îî‚îÄ components/
   ‚îú‚îÄ AIProviderSettings.tsx
   ‚îî‚îÄ ...
supabase/
public/
```
G·ª£i √Ω b·ªï sung:
- services/ingestion/: parser, chunker, embedQueue
- services/retrieval/: vectorClient, rerank (n·∫øu th√™m)
- utils/: tokenCounting, textNormalization
- tests/: unit, integration, provider, e2e

## 7. Bi·∫øn m√¥i tr∆∞·ªùng (.env)
Hi·ªán h·ªØu trong .env.example:
```
# OpenAI
VITE_OPENAI_API_KEY=sk-proj-xxxxx
VITE_OPENAI_MODEL=gpt-4o-mini

# Google Gemini
VITE_GEMINI_API_KEY=AIzaSyxxxxx
VITE_GEMINI_MODEL=gemini-1.5-flash-latest

# Ollama (local)
VITE_OLLAMA_BASE_URL=http://localhost:11434
VITE_OLLAMA_MODEL=llama3.1

# Default
VITE_DEFAULT_AI_PROVIDER=gemini
```
B·ªï sung (t·ª´ t√†i li·ªáu ki·∫øn tr√∫c ‚Äì n·∫øu c·∫ßn m·ªü r·ªông):
```
# Anthropic
VITE_ANTHROPIC_API_KEY=
VITE_ANTHROPIC_MODEL=claude-3-haiku-20240307

# Groq
VITE_GROQ_API_KEY=
VITE_GROQ_MODEL=llama-3.1-70b-versatile
```
Khuy·∫øn ngh·ªã th√™m (t√πy t∆∞∆°ng lai):
```
# Retrieval / Embedding (n·∫øu d√πng service b√™n ngo√†i)
VITE_EMBEDDING_MODEL=
VITE_VECTOR_NAMESPACE=
# Logging / Observability
VITE_LOG_LEVEL=info
# Feature flags
VITE_ENABLE_STREAMING=true
```
L∆∞u √Ω:
- Bi·∫øn b·∫Øt ƒë·∫ßu b·∫±ng VITE_ s·∫Ω ƒë∆∞·ª£c expose ra frontend (kh√¥ng ƒë·ªÉ kh√≥a nh·∫°y c·∫£m server-only trong bi·∫øn n√†y n·∫øu kh√¥ng c·∫ßn backend ri√™ng).
- Kh√¥ng commit kh√≥a th·∫≠t l√™n repo.

## 8. Scripts & Quy tr√¨nh ph√°t tri·ªÉn
(package.json)
```
dev              ‚Üí vite
build            ‚Üí vite build
build:dev        ‚Üí vite build --mode development
lint             ‚Üí eslint .
preview          ‚Üí vite preview
test             ‚Üí vitest
test:ui          ‚Üí vitest --ui
test:run         ‚Üí vitest run
test:coverage    ‚Üí vitest run --coverage
```
Quy tr√¨nh g·ª£i √Ω:
1. Sao ch√©p `.env.example` ‚Üí `.env`.
2. C√†i ƒë·∫∑t: `npm install`
3. Ch·∫°y dev: `npm run dev`
4. Test nhanh tr∆∞·ªõc commit: `npm run lint && npm run test:run`.

## 9. Pipeline Ingestion T√†i li·ªáu
C√°c b∆∞·ªõc:
1. Upload: ng∆∞·ªùi d√πng ch·ªçn file PDF.
2. Ki·ªÉm tra ƒë·ªãnh d·∫°ng / k√≠ch th∆∞·ªõc / checksum (ch·ªëng tr√πng).
3. Parse: pdfjs-dist ‚Üí l·∫•y text t·ª´ng trang.
4. OCR fallback: n·∫øu trang r·ªóng / t·ª∑ l·ªá k√Ω t·ª± th·∫•p ‚Üí tesseract.js.
5. Clean: lo·∫°i header/footer l·∫∑p, chu·∫©n h√≥a kho·∫£ng tr·∫Øng, unify newline.
6. Chunking: theo token/char threshold (v√≠ d·ª• 1000‚Äì1500 tokens) + overlap (100‚Äì150 tokens).
7. Hash chunk: tr√°nh embed l·∫°i.
8. Embed batch: g·ª≠i theo l√¥ gi·∫£m overhead HTTP.
9. L∆∞u vector: (Supabase pgvector ho·∫∑c adapter).
10. Index metadata: page, offset, file_id, th·ªùi gian ingest.

C·∫£i ti·∫øn (t√†i li·ªáu UPLOAD_IMPROVEMENTS.md & FIX_PDF_UPLOAD.md):
- Gi·∫£m l·ªói PDF scan.
- T·ªëi ∆∞u k√≠ch th∆∞·ªõc batch embedding.
- ƒêi·ªÅu ch·ªânh overlap ƒë·ªông theo m·∫≠t ƒë·ªô ng·ªØ nghƒ©a.

## 10. Retrieval & Query Flow
1. Nh·∫≠n query ng∆∞·ªùi d√πng.
2. Chu·∫©n h√≥a (lowercase nh·∫π / remove noise? ‚Äì kh√¥ng ph√° d·∫•u ti·∫øng Vi·ªát).
3. Embedding query ‚Üí vector.
4. Vector search top-K (v√≠ d·ª• k=5‚Äì8).
5. (T√πy ch·ªçn) Rerank / filter theo ngu·ªìn, th·ªùi gian.
6. Compose context (gi·ªõi h·∫°n t·ªïng tokens).
7. Pass sang provider generate ‚Üí stream token ‚Üí hi·ªÉn th·ªã incremental.

## 11. Prompt Composition & Generation
C·∫•u tr√∫c prompt (g·ª£i √Ω):
```
System: Vai tr√≤, phong c√°ch tr·∫£ l·ªùi, ng√¥n ng·ªØ (vi/en)
Context: <Concatenate normalized top-K chunks with source tags>
User: <Original user query>
Guidelines: N·∫øu kh√¥ng ch·∫Øc, n√≥i r√µ.
```
T·ªëi ∆∞u:
- G·∫Øn metadata: [Doc:filename.pdf#page=12]
- Tr√°nh v∆∞·ª£t context window: c·∫Øt b·ªõt chunk d√†i / t√≥m t·∫Øt trung gian.

## 12. T·ªëi ∆∞u chi ph√≠ & Fallback chi·∫øn l∆∞·ª£c
Theo b·∫£ng cost trong t√†i li·ªáu:
- Default: Gemini Flash (mi·ªÖn ph√≠ / nhanh).
- Local offline: Ollama (llama3.1:8b).
- N√¢ng ch·∫•t l∆∞·ª£ng: OpenAI GPT-4o-mini.
- Reasoning s√¢u: Claude Sonnet (khi c·∫ßn logic ph·ª©c t·∫°p).
Fallback logic (v√≠ d·ª•):
1. Primary provider generate.
2. N·∫øu timeout / rate limit ‚Üí chuy·ªÉn sang provider th·ª© hai.
3. Log metric (latency, success ratio per provider) gi√∫p t∆∞∆°ng lai adaptive routing.

Cache:
- Embedding dedup b·∫±ng hashing chunk.
- Response caching cho c√¢u h·ªèi l·∫∑p (l∆∞u √Ω invalidation khi corpus thay ƒë·ªïi).

## 13. Testing Strategy
- Unit:
  - Provider adapter mock (OpenAI/Gemini‚Ä¶).
  - Chunking / normalization utils.
- Integration:
  - Query ‚Üí retrieval ‚Üí prompt assembly (mock model).
  - Ingestion partial pipeline test.
- Contract:
  - Interface provider kh√¥ng ƒë·ªïi signature (snapshot types ho·∫∑c test runtime).
- UI:
  - AIProviderSettings, Upload form, Chat panel.
- Performance (t√πy ch·ªçn):
  - Th·ªùi gian embed batch vs single.
- Coverage:
  - `npm run test:coverage`.

## 14. Production Hardening Checklist
| H·∫°ng m·ª•c | M·ª©c ƒë·ªô | Ghi ch√∫ |
|----------|--------|--------|
| Structured Logging | Cao | JSON logs g·∫Øn trace ID |
| Retry & Backoff | Cao | Provider 429/5xx |
| Rate Limiting | Cao | Per user / IP |
| Token Usage Accounting | Trung | Log input/output tokens |
| Secrets Mgmt | Cao | Kh√¥ng ph∆°i API key raw client n·∫øu kh√¥ng c·∫ßn |
| Streaming Partial Fail Handling | Trung | Cancel mid-stream |
| Healthcheck Endpoint | Trung | Ping vector store + provider HEAD |
| Alerting | Trung | Error rate threshold |
| Vector Migration Plan | Th·∫•p | Khi ƒë·ªïi schema embeddings |
| Model Version Pinning | Cao | Tr√°nh drift ch·∫•t l∆∞·ª£ng |

## 15. B·∫£o m·∫≠t & Qu·∫£n l√Ω kh√≥a
- Bi·∫øn VITE_ l√† public ‚Üí Ch·ªâ ƒë·ªÉ kh√≥a model free/kh√¥ng nh·∫°y c·∫£m (Gemini free). Kh√≥a tr·∫£ ph√≠ n√™n ƒëi qua backend proxy (n·∫øu b·ªï sung backend).
- Kh√¥ng commit .env.
- Th√™m secure storage (n·∫øu c√≥ backend) ƒë·ªÉ quay v√≤ng (rotate) keys.
- Gi·∫£m r·ªßi ro prompt injection: l·ªçc user input, t√°ch system instructions r√µ r√†ng.

## 16. T√≠ch h·ª£p v√†o h·ªá th·ªëng kh√°c (Embedding / API)
Pattern:
- Backend module: expose h√†m `answerQuestion(query, options)` tr·∫£ v·ªÅ stream.
- UI embed: t√°ch component ChatPanel + ProviderSelector.
- API g·ª£i √Ω:
  - POST /api/ingest {file_id}
  - POST /api/query {query, topK?}
  - GET  /api/sources
- Auth: Supabase JWT ho·∫∑c custom token ‚Üí map user_id trong logging / rate limit.

## 17. Roadmap g·ª£i √Ω m·ªü r·ªông
- Conversation Memory Summarization (gi·∫£m chi·ªÅu d√†i ng·ªØ c·∫£nh).
- Hybrid Retrieval (keyword + vector).
- Reranking (LLM ho·∫∑c cross-encoder).
- Feedback Loop (thumbs up/down ‚Üí c·∫£i thi·ªán rerank).
- Adaptive Provider Routing (ML policy).
- Cost Dashboard UI.
- Differential Embedding Update (ch·ªâ re-embed thay ƒë·ªïi).

## 18. Kh·∫Øc ph·ª•c s·ª± c·ªë (Troubleshooting)
| V·∫•n ƒë·ªÅ | Nguy√™n nh√¢n | Kh·∫Øc ph·ª•c |
|--------|-------------|-----------|
| L·ªói 401 khi g·ªçi model | Sai API key | Ki·ªÉm tra .env & reload |
| R·ªóng n·ªôi dung PDF | File scan ·∫£nh | B·∫≠t OCR fallback |
| K·∫øt qu·∫£ l·∫°c ƒë·ªÅ | Chunk qu√° nh·ªè / context thi·∫øu | TƒÉng CHUNK_SIZE ho·∫∑c top-K |
| Ch·∫≠m | Batch embedding nh·ªè / provider free qu√° t·∫£i | TƒÉng batch size / fallback provider |
| Token over-limit | Qu√° nhi·ªÅu chunk | R√∫t g·ªçn / t√≥m t·∫Øt chunk d√†i |
| Kh√¥ng stream | Provider kh√¥ng h·ªó tr·ª£ ho·∫∑c flag t·∫Øt | Ki·ªÉm tra supportsStreaming & config |

## 19. T√†i li·ªáu tham chi·∫øu n·ªôi b·ªô
- AI_BACKEND_ARCHITECTURE.md
- AI_BACKEND_IMPLEMENTATION.md
- AI_PROVIDER_IMPLEMENTATION.md
- AI_IMPLEMENTATION_SUMMARY.md
- IMPLEMENTATION_SUMMARY.md
- QUICK_START_AI.md
- INTEGRATION_GUIDE.md
- PRODUCTION_FEATURES.md
- UPLOAD_IMPROVEMENTS.md
- FIX_PDF_UPLOAD.md
- TEST_GUIDE.md
- CODEBASE_SCAN_REPORT.md

## 20. Thi·∫øu / C·∫ßn b·ªï sung (Ghi ch√∫ duy tr√¨)
- Ch∆∞a c√≥ LICENSE.
- N√™n th·ªëng nh·∫•t package manager (npm vs bun lockfile).
- Th√™m t√†i li·ªáu chi ti·∫øt src/ (khi c·∫•u tr√∫c ·ªïn ƒë·ªãnh).
- Xem x√©t th√™m CHANGELOG.md n·∫øu release versioned.

## 21. License (Tr·∫°ng th√°i)
Ch∆∞a khai b√°o. Khuy·∫øn ngh·ªã th√™m MIT ho·∫∑c Apache-2.0 ƒë·ªÉ m·ªü r·ªông s·ª≠ d·ª•ng c·ªông ƒë·ªìng.

---

Last Updated: (c·∫≠p nh·∫≠t khi commit)  
Maintainer: @Khogao  
